(window.webpackJsonp=window.webpackJsonp||[]).push([[99],{633:function(t,a,s){"use strict";s.r(a);var e=s(5),r=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"nodejs的爬虫"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nodejs的爬虫"}},[t._v("#")]),t._v(" nodejs的爬虫")]),t._v(" "),s("div",{staticClass:"custom-block tip"},[s("p",[t._v("实际上爬虫并没有非常的复杂，主要就是请求网站地址，将网站的发回的数据进行数据处理，实现的方法又很多种，无非就是那种方法更加的便捷，当然网站开发者也会想办法来反爬，这就是一场关于双方的博弈。")])]),t._v(" "),s("h2",{attrs:{id:"依赖包"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#依赖包"}},[t._v("#")]),t._v(" 依赖包")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("axios")])])]),t._v(" "),s("blockquote",[s("p",[t._v("用于发送网络请求")])]),t._v(" "),s("ul",[s("li",[s("code",[t._v("cheerio")])])]),t._v(" "),s("blockquote",[s("p",[t._v("将请求回来的数据进行处理，"),s("code",[t._v("cheerio")]),t._v("可以像jq一样在弄得中处理网站发来的内容，非常好用")])]),t._v(" "),s("h2",{attrs:{id:"实战"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实战"}},[t._v("#")]),t._v(" 实战")]),t._v(" "),s("blockquote",[s("p",[t._v("我随便找了个电影网站 "),s("code",[t._v("https://www.piaohua.com/")]),t._v(" 尝试去爬取它的数据")])]),t._v(" "),s("h3",{attrs:{id:"安装依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#安装依赖"}},[t._v("#")]),t._v(" 安装依赖")]),t._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("npm i axios cheerio\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("h3",{attrs:{id:"使用axios的get请求目标地址"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用axios的get请求目标地址"}},[t._v("#")]),t._v(" 使用axios的get请求目标地址")])])}),[],!1,null,null,null);a.default=r.exports}}]);